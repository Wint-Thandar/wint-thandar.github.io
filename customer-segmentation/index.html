<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
    <title>The &quot;You Are What You Eat&quot; Customer Segmentation</title>
    <meta name="description" content="Hi, I'm Wint! I'm a professional working in software technology. This is my professional portfolio showcasing a variety of projects/tutorials that I have done by following the courses or books. You can visit my Github & LinkedIn profiles or download my resume using the links." />
    <link rel="canonical" href="/customer-segmentation/">
    <link rel="alternate" type="application/rss+xml" title="Wint Thandar Oo" href="/feed.xml">
    <!-- Google Font -->
    <link href="https://fonts.googleapis.com/css?family=Nunito:400,700" rel="stylesheet">
    <!-- Ionicons -->
    <link href="https://unpkg.com/ionicons@4.2.2/dist/css/ionicons.min.css" rel="stylesheet">
    <link rel="stylesheet" href="/assets/css/main.css">
	
	<!-- Google tag (gtag.js) -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-5Q5EYVF2FJ"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'G-5Q5EYVF2FJ');
	</script>
</head>

<body>
    <header class="header">
	<div class="container">
		<div class="row">
			<div class="col col-12">
				<div class="header-box">
					<div class="col col-3 wd-mob">
						
						<a href="/" class="header-avatar">
							<img src="/img/profile_picture.jpg" class="header-avatar-img" alt="Wint Thandar Oo">
						</a>
						
					</div>
					<hr>
					<div class="col col-9 wd-mob">
						
						<h1 class="header-title">Wint Thandar Oo</h1>
						
						
						<h1 class="header-subtitle">Professional <span style="color:#f58506"> Portfolio </span></h1>
						
						
						<p class="header-tagline">Hi, I'm Wint! I'm a professional working in software technology. This is my professional portfolio showcasing a variety of projects/tutorials that I have done by following the courses or books. You can visit my Github & LinkedIn profiles or download my resume using the links.</p>
						
						<div class="menu-links">
							<ul class="list-reset">
								<li class="item"><a class="item-link"><i class="ion ion-ios-pin"></i> Yangon, Myanmar</a></li>
								<li class="item"><a class="item-link" href="https://github.com/Wint-Thandar"><i class="ion ion-logo-github"></i> Github</a></li>
								<li class="item"><a class="item-link" href="https://www.linkedin.com/in/wintthandaroo/"><i class="ion ion-logo-linkedin"></i> Linkedln</a></li>
								<li class="item"><a class="item-link" href="/docs/Wint%20Thandar%20Oo%20Resume%202023.docx"><i class="ion ion-ios-document"></i> Resume</a></li>
							</ul>
						</div>
					</div>
				</div>
			</div>
		</div>
	</div>
</header> <!-- /.header -->
    <div class="container">
    <div class="row">
        <div class="col col-12">
            <div class="post-image-box">
                <div class="post-image" style="background-image: url(/img//posts/clustering-title-img.png)"></div>
            </div>
        </div>
    </div>
</div>
<div class="container">
    <div class="row">
        <article class="col col-12 col-t-12 post">
            <div class="post-content">
                <div class="post-head">
                    
                    <div class="post-tag">
                        
                        <a href="/tags#Customer Segmentation" class="tag">Customer Segmentation</a>
                        
                        <a href="/tags#Machine Learning" class="tag">Machine Learning</a>
                        
                        <a href="/tags#Clustering" class="tag">Clustering</a>
                        
                        <a href="/tags#Python" class="tag">Python</a>
                        
                    </div>
                    
                    <h1 class="post-title">The &quot;You Are What You Eat&quot; Customer Segmentation</h1>
                    <div class="post-info">
                        <div class="post-time">
                            <span class="page__meta"><i class="ion ion-md-time"></i><span class="reading-time" title="Estimated read time">
    
    15 min read time
</span></span>
                        </div>
                    </div>
                </div>
                <div class="post-body">
                    <ul id="toc" class="toc__list">
<li class="toc-entry toc-h1"><a href="#project-overview">Project Overview</a>
<ul class="toc__sublist">
<li class="toc-entry toc-h3"><a href="#project-purpose">Project Purpose</a></li>
<li class="toc-entry toc-h3"><a href="#github-repository-link">GitHub Repository Link</a></li>
<li class="toc-entry toc-h3"><a href="#context">Context</a></li>
<li class="toc-entry toc-h3"><a href="#actions">Actions</a></li>
<li class="toc-entry toc-h3"><a href="#results">Results</a></li>
<li class="toc-entry toc-h3"><a href="#growthnext-steps">Growth/Next Steps</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#data-overview">Data Overview</a></li>
<li class="toc-entry toc-h1"><a href="#k-means">K-Means</a>
<ul class="toc__sublist">
<li class="toc-entry toc-h3"><a href="#concept-overview">Concept Overview</a></li>
<li class="toc-entry toc-h3"><a href="#data-preprocessing">Data Preprocessing</a></li>
<li class="toc-entry toc-h3"><a href="#finding-a-good-value-for-k">Finding A Good Value For k</a></li>
<li class="toc-entry toc-h3"><a href="#model-fitting">Model Fitting</a></li>
<li class="toc-entry toc-h3"><a href="#append-clusters-to-customers">Append Clusters To Customers</a></li>
<li class="toc-entry toc-h3"><a href="#cluster-profiling">Cluster Profiling</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#application">Application</a></li>
</ul><h1 id="project-overview">
<a class="anchor" href="#project-overview" aria-hidden="true"><span class="octicon octicon-link"></span></a>Project Overview</h1>
<h3 id="project-purpose">
<a class="anchor" href="#project-purpose" aria-hidden="true"><span class="octicon octicon-link"></span></a>Project Purpose</h3>
<p>The purpose of this project is to segment up the customer base in order to increase business understanding, and to enhance the relevancy of targeted messaging &amp; customer communications, using k-means clustering.<br><br></p>

<h3 id="github-repository-link">
<a class="anchor" href="#github-repository-link" aria-hidden="true"><span class="octicon octicon-link"></span></a>GitHub Repository Link</h3>
<p>The source code and datasets for this project can be found at my <a href="https://github.com/Wint-Thandar/python-projects/tree/main/unsupervised_kmeans_clustering">GitHub repository</a>.<br><br></p>

<h3 id="context">
<a class="anchor" href="#context" aria-hidden="true"><span class="octicon octicon-link"></span></a>Context</h3>
<p>The Senior Management team from a supermarket chain client were disagreeing about how customers shopped and how lifestyle choices affected which food areas customers purchased from, or notably, did not purchase from.</p>

<p>They asked a consulting firm to use data and Machine Learning to segment their customers based on engagement with each major food category. This would aid the client’s understanding of their customer base and enhance the relevance of targeted messaging and customer communications.<br><br></p>

<h3 id="actions">
<a class="anchor" href="#actions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Actions</h3>
<p>The first step is to compile the necessary data from several database tables, namely the <code class="language-plaintext highlighter-rouge">transactions</code> table and the <code class="language-plaintext highlighter-rouge">product_areas</code> table. The relevant information is joined together using <code class="language-plaintext highlighter-rouge">Pandas</code>, and the transactional data is aggregated across product areas, from the most recent six months to a customer level. The final data for clustering is, for each customer, the percentage of sales allocated to each product area.</p>

<p>As a starting point, k-means clustering is tested and applied for this task. Some data pre-processing is required, most importantly feature scaling to ensure all variables exist on the same scale - a very important consideration for distance-based algorithms such as k-means.</p>

<p>As k-means is an <em>unsupervised learning approach</em>, in other words there are no labels - a process known as <em>Within Cluster Sum of Squares (WCSS)</em> is used to understand what a “good” number of clusters or segments is.</p>

<p>Based on this, the k-means algorithm is applied onto the product area data, the clusters are appended to the customer base, and the resulting customer segments are profiled to understand the differentiating factors.<br><br></p>

<h3 id="results">
<a class="anchor" href="#results" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results</h3>
<p>Based on iterative testing using WCSS, a customer segmentation with 3 clusters is settled on. These clusters range in size, with Cluster 0 accounting for <code class="language-plaintext highlighter-rouge">73.6%</code> of the customer base, Cluster 2 accounting for <code class="language-plaintext highlighter-rouge">14.6%</code>, and Cluster 1 accounting for <code class="language-plaintext highlighter-rouge">11.8%</code>.</p>

<p>There are some extremely interesting findings from profiling the clusters.</p>

<p>For <em>Cluster 0</em> a significant portion of spend is allocated to each of the product areas - showing customers without any particular dietary preference.</p>

<p>For <em>Cluster 1</em> quite high proportions of spend are allocated to Fruit &amp; Vegetables, but very little to the Dairy &amp; Meat product areas. It could be hypothesized that these customers are following a vegan diet.</p>

<p>Finally customers in <em>Cluster 2</em> spend significant portions within Dairy, Fruit &amp; Vegetables, but very little in the Meat product area - so similarly, an early hypothesis is that these customers are more along the lines of those following a vegetarian diet.</p>

<p>To help embed this segmentation into the business, “You Are What You Eat” has been proposed as a name for the segmentation.<br><br></p>

<h3 id="growthnext-steps">
<a class="anchor" href="#growthnext-steps" aria-hidden="true"><span class="octicon octicon-link"></span></a>Growth/Next Steps</h3>
<p>It would be interesting to run this clustering/segmentation at a lower level of product areas, so rather than just the four areas of Meat, Dairy, Fruit, Vegetables - clustering spend across the sub-categories <em>below</em> those categories. This would mean more specific clusters could be created, and an even more granular understanding of dietary preferences within the customer base could be obtained.</p>

<p>Here the focus has just been on variables directly linked to sales - it could be interesting to also include customer metrics such as distance to store, gender etc to give an even more well-rounded customer segmentation.</p>

<p>It would be useful to test other clustering approaches such as hierarchical clustering or DBSCAN to compare the results.<br><br></p>

<hr>
<h1 id="data-overview">
<a class="anchor" href="#data-overview" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data Overview</h1>
<p>The primary focus is on identifying customer segments based on their transactions within the <em>food</em> based product areas, so only those will be selected.</p>

<p>The code below:</p>

<ul>
  <li>Import the required python packages &amp; libraries</li>
  <li>Import the tables from the database</li>
  <li>Merge the tables to tag on <em><code class="language-plaintext highlighter-rouge">product_area_name</code></em> which only exists in the <em><code class="language-plaintext highlighter-rouge">product_areas</code></em> table</li>
  <li>Drop the non-food categories</li>
  <li>Aggregate the sales data for each product area, at customer level</li>
  <li>Pivot the data to get it into the right format for clustering</li>
  <li>Change the values from raw dollars, into a percentage of spend for each customer (to ensure each customer is comparable)<br>
</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># import required Python packages
</span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># import tables from database
</span><span class="n">transactions</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s">'grocery_database.xlsx'</span><span class="p">,</span> <span class="n">sheet_name</span><span class="o">=</span><span class="s">'transactions'</span><span class="p">)</span>
<span class="n">product_areas</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s">'grocery_database.xlsx'</span><span class="p">,</span> <span class="n">sheet_name</span><span class="o">=</span><span class="s">'product_areas'</span><span class="p">)</span>

<span class="c1"># merge data on product area id
</span><span class="n">transactions</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">transactions</span><span class="p">,</span> <span class="n">product_areas</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s">'inner'</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s">'product_area_id'</span><span class="p">)</span>

<span class="c1"># drop the non-food category
</span><span class="n">transactions</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">transactions</span><span class="p">[</span><span class="n">transactions</span><span class="p">[</span><span class="s">'product_area_name'</span><span class="p">]</span> <span class="o">==</span> <span class="s">'Non-Food'</span><span class="p">].</span><span class="n">index</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># aggregate sales at customer level by product area
</span><span class="n">transactions_summary</span> <span class="o">=</span> <span class="n">transactions</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'customer_id'</span><span class="p">,</span> <span class="s">'product_area_name'</span><span class="p">])[</span><span class="s">'sales_cost'</span><span class="p">].</span><span class="nb">sum</span><span class="p">()</span>

<span class="c1"># pivot data to place product area as columns
</span><span class="n">transactions_summary_pivot</span> <span class="o">=</span> <span class="n">transactions</span><span class="p">.</span><span class="n">pivot_table</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="s">'customer_id'</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="s">'product_area_name'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="s">'sales_cost'</span><span class="p">,</span> <span class="n">aggfunc</span><span class="o">=</span><span class="s">'sum'</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">margins</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">margins_name</span><span class="o">=</span><span class="s">'Total'</span><span class="p">).</span><span class="n">rename_axis</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># turn sales into % sales
</span><span class="n">transactions_summary_pivot</span> <span class="o">=</span> <span class="n">transactions_summary_pivot</span><span class="p">.</span><span class="n">div</span><span class="p">(</span><span class="n">transactions_summary_pivot</span><span class="p">[</span><span class="s">'Total'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># drop the total column
</span><span class="n">data_for_clustering</span> <span class="o">=</span> <span class="n">transactions_summary_pivot</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'Total'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>
<p><br></p>

<p>After the data pre-processing using Pandas, we have a dataset for clustering that looks like the below sample:<br></p>

<table>
  <thead>
    <tr>
      <th><strong>customer_id</strong></th>
      <th><strong>dairy</strong></th>
      <th><strong>fruit</strong></th>
      <th><strong>meat</strong></th>
      <th><strong>vegetables</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2</td>
      <td>0.246</td>
      <td>0.198</td>
      <td>0.394</td>
      <td>0.162</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.142</td>
      <td>0.233</td>
      <td>0.528</td>
      <td>0.097</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.341</td>
      <td>0.245</td>
      <td>0.272</td>
      <td>0.142</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.213</td>
      <td>0.250</td>
      <td>0.430</td>
      <td>0.107</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.180</td>
      <td>0.178</td>
      <td>0.546</td>
      <td>0.095</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.000</td>
      <td>0.517</td>
      <td>0.000</td>
      <td>0.483</td>
    </tr>
  </tbody>
</table>

<p><br></p>

<p>The data is at customer level, and we have a column for each of the highest level food product areas.  Within each of those we have the <em>percentage</em> of sales that each customer allocated to that product area over the past six months.<br></p>

<hr>
<h1 id="k-means">
<a class="anchor" href="#k-means" aria-hidden="true"><span class="octicon octicon-link"></span></a>K-Means</h1>

<h3 id="concept-overview">
<a class="anchor" href="#concept-overview" aria-hidden="true"><span class="octicon octicon-link"></span></a>Concept Overview</h3>
<p>K-Means is an <em>unsupervised learning</em> algorithm, meaning that it does not look to predict known labels or values, but instead looks to isolate patterns within unlabelled data.</p>

<p>The algorithm works in a way where it partitions data-points into distinct groups (clusters) based upon their <em>similarity</em> to each other.</p>

<p>This similarity is most often the eucliedean (straight-line) distance between data-points in n-dimensional space.  Each variable that is included lies on one of the dimensions in space.</p>

<p>The number of distinct groups (clusters) is determined by the value that is set for “k”.</p>

<p>The algorithm does this by iterating over four key steps, namely:<br></p>

<ol>
  <li>It selects “k” random points in space (these points are known as centroids)</li>
  <li>It then assigns each of the data points to the nearest centroid (based upon euclidean distance)</li>
  <li>It then repositions the centroids to the <em>mean</em> dimension values of it’s cluster</li>
  <li>It then reassigns each data-point to the nearest centroid</li>
</ol>

<p>Steps 3 &amp; 4 continue to iterate until no data-points are reassigned to a closer centroid.<br><br></p>

<h3 id="data-preprocessing">
<a class="anchor" href="#data-preprocessing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data Preprocessing</h3>
<p>There are three vital preprocessing steps for k-means, namely:<br></p>

<ul>
  <li>Missing values in the data</li>
  <li>The effect of outliers</li>
  <li>Feature Scaling<br><br>
</li>
</ul>

<h5 id="missing-values">Missing Values</h5>
<p>Missing values can cause issues for k-means, as the algorithm won’t know where to plot those data-points along the dimension where the value is not present.  If we have observations with missing values, the most common options are to either remove the observations, or to use an imputer to fill-in or to estimate what those value might be.</p>

<p>As we aggregated our data for each customer, we actually don’t suffer from missing values so we don’t need to deal with that here.<br><br></p>

<h5 id="outliers">Outliers</h5>
<p>As k-means is a distance based algorithm, outliers can cause problems. The main concern arises when scaling input variables, a very important step for a distance based algorithm.</p>

<p>The goal is to prevent any variables from clustering together due to a single outlier value, which would make it difficult to compare their values to the other input variables. Rigorous investigation of outliers is always recommended. Fortunately, in this case involving percentages, this issue is not encountered.<br><br></p>

<h5 id="feature-scaling">Feature Scaling</h5>
<p>Again, as k-means is a distance based algorithm, meaning it relies on understanding how similar or different data points are across dimensions in n-dimensional space, the application of Feature Scaling is extremely important.</p>

<p>Feature Scaling forces values from different columns to exist on the same scale, enhancing the learning capabilities of the model. There are two common approaches: Standardisation and Normalisation.</p>

<p>Standardisation rescales data to have a mean of <code class="language-plaintext highlighter-rouge">0</code> and standard deviation of <code class="language-plaintext highlighter-rouge">1</code>, with most datapoints falling between <code class="language-plaintext highlighter-rouge">-4</code> and <code class="language-plaintext highlighter-rouge">+4</code>.</p>

<p>Normalisation rescales datapoints to exist between <code class="language-plaintext highlighter-rouge">0</code> and <code class="language-plaintext highlighter-rouge">1</code>.</p>

<p>For k-means clustering, either approach is far better than no scaling. Here, normalisation will be applied to ensure all variables have the same <code class="language-plaintext highlighter-rouge">0</code> to <code class="language-plaintext highlighter-rouge">1</code> range, enabling the k-means algorithm to judge each variable in the same context. Standardisation <em>can</em> result in different ranges variable to variable, which is less useful here (although not always true).</p>

<p>Another reason to choose Normalisation is that the scaled data will all be between <code class="language-plaintext highlighter-rouge">0</code> and <code class="language-plaintext highlighter-rouge">1</code>, compatible with any categorical variables encoded as <code class="language-plaintext highlighter-rouge">1</code>’s and <code class="language-plaintext highlighter-rouge">0</code>’s.</p>

<p>In this case, percentages are already between <code class="language-plaintext highlighter-rouge">0</code> and <code class="language-plaintext highlighter-rouge">1</code>. Normalisation is still applied for the following reason: One product area may dominate sales, and end up dominating the clustering space. Normalising all variables will spread even smaller product areas proportionately between <code class="language-plaintext highlighter-rouge">0</code> and <code class="language-plaintext highlighter-rouge">1</code>.</p>

<p>The code below uses <code class="language-plaintext highlighter-rouge">MinMaxScaler</code> from <code class="language-plaintext highlighter-rouge">scikit-learn</code> to apply Normalisation. A new scaled object is created because the actual percentages may make more intuitive business sense when profiling clusters later, so it’s good to have both options available.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create scaler object
</span><span class="n">scale_norm</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>

<span class="c1"># normalise the data
</span><span class="n">data_for_clustering_scaled</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scale_norm</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data_for_clustering</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="n">data_for_clustering</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
</code></pre></div></div>

<p><br></p>

<h3 id="finding-a-good-value-for-k">
<a class="anchor" href="#finding-a-good-value-for-k" aria-hidden="true"><span class="octicon octicon-link"></span></a>Finding A Good Value For k</h3>
<p>At this point here, the data is ready to be fed into the k-means clustering algorithm. Before that, it’s important to understand what number of clusters the data should be split into.</p>

<p>In the world of unsupervised learning, there isn’t a definitive <em>right or wrong</em> value for this. It truly depends on the data being dealt with, as well as the specific scenario in which the algorithm is being used. For our client, having a very high number of clusters might not be appropriate, as it would be too challenging for the business to grasp the nuances of each cluster in a way that allows them to apply the right strategies.</p>

<p>Finding the “right” value for k can feel more like an art than a science, but there are some data-driven approaches that can be helpful!</p>

<p>The approach being utilized here is known as the <em>Within Cluster Sum of Squares (WCSS)</em>, which measures the sum of the squared Euclidean distances that data points lie from their closest centroid. WCSS can provide insight into the point at which adding more clusters offers little extra benefit in terms of separating the data.</p>

<p>By default, the k-means algorithm within <code class="language-plaintext highlighter-rouge">scikit-learn</code> uses <code class="language-plaintext highlighter-rouge">k = 8</code>, which means it aims to split the data into eight distinct clusters. The goal is to find a better value that fits the data and the task at hand.</p>

<p>In the code below, multiple values for k will be tested, and the changes in the WCSS metric will be plotted. As the value of k increases (in other words, as the number of centroids or clusters increases), the WCSS value will consistently decrease. However, these decreases will become smaller and smaller with each additional centroid. The aim is to identify a point where this decrease is quite noticeable <em>before</em> reaching a point of diminishing returns.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># set up range for search, and empty list to append wcss scores to
</span><span class="n">k_values</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">wcss_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># loop through each possible value of k, fit to the data, append the wcss score
</span><span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">k_values</span><span class="p">:</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">kmeans</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data_for_clustering_scaled</span><span class="p">)</span>
    <span class="n">wcss_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">kmeans</span><span class="p">.</span><span class="n">inertia_</span><span class="p">)</span>

<span class="c1"># plot wcss by k
</span><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k_values</span><span class="p">,</span> <span class="n">wcss_list</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Within Cluster Sum of Square - by k'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'k'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'WCSS Score'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p><br></p>

<p>Above code gives us the below plot - which visualises our results.<br>
<img src="/img/posts/kmeans-optimal-k-value-plot.png" alt="alt text" title="K-Means Optimal k Value Plot"><br></p>

<p>Based upon the shape of the above plot - there does appear to be an elbow at <code class="language-plaintext highlighter-rouge">k = 3</code>.  Prior to that we see a significant drop in the WCSS score, but following the decreases are much smaller, meaning this could be a point that suggests adding <em>more clusters</em> will provide little extra benefit in terms of separating our data. A small number of clusters can be beneficial when considering how easy it is for the business to focus on, and understand, each - so we will continue on, and fit our k-means clustering solution with <code class="language-plaintext highlighter-rouge">k = 3</code>.<br><br></p>

<h3 id="model-fitting">
<a class="anchor" href="#model-fitting" aria-hidden="true"><span class="octicon octicon-link"></span></a>Model Fitting</h3>
<p>The below code will instantiate the k-means object using a value for <code class="language-plaintext highlighter-rouge">k</code> equal to <code class="language-plaintext highlighter-rouge">3</code>.  We then fit this object to our scaled dataset to separate our data into three distinct segments or clusters.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># instantiate our k-means object
</span><span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>

<span class="c1"># fit to our data
</span><span class="n">kmeans</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data_for_clustering_scaled</span><span class="p">)</span>
</code></pre></div></div>

<p><br></p>

<h3 id="append-clusters-to-customers">
<a class="anchor" href="#append-clusters-to-customers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Append Clusters To Customers</h3>
<p>With the k-means algorithm fitted to the data, we can now append those clusters to the original dataset, meaning that each customer is tagged with the cluster number that they most closely fit into based upon their sales data over each product area.</p>

<p>In the code below, this cluster number is tagged onto the original dataframe.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># add cluster labels to the original data
</span><span class="n">data_for_clustering</span><span class="p">[</span><span class="s">'cluster'</span><span class="p">]</span> <span class="o">=</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">labels_</span>
</code></pre></div></div>

<p><br></p>

<h3 id="cluster-profiling">
<a class="anchor" href="#cluster-profiling" aria-hidden="true"><span class="octicon octicon-link"></span></a>Cluster Profiling</h3>
<p>Once the data is separated into distinct clusters, the client needs to understand <em>what</em> is driving the separation. This allows the business to comprehend the customers within each cluster and the behaviors that make them unique.</p>

<p><br></p>

<h5 id="cluster-sizes">Cluster Sizes</h5>

<p>In the below code the number of customers that fall into each cluster is assessed.<br></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># check cluster sizes
</span><span class="n">data_for_clustering</span><span class="p">[</span><span class="s">"cluster"</span><span class="p">].</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>
<p><br></p>

<p>Running that code shows us that the three clusters are different in size, with the following proportions:</p>

<ul>
  <li>Cluster 0: <strong><code class="language-plaintext highlighter-rouge">73.6%</code></strong> of customers</li>
  <li>Cluster 2: <strong><code class="language-plaintext highlighter-rouge">14.6%</code></strong> of customers</li>
  <li>Cluster 1: <strong><code class="language-plaintext highlighter-rouge">11.8%</code></strong> of customers</li>
</ul>

<p>Based on these results, there is a noticeable skew toward Cluster 0, with Cluster 1 and Cluster 2 being proportionally smaller. This isn’t a matter of right or wrong; it simply reveals pockets within the customer base that exhibit different behaviors - and this is precisely what is desired.<br><br></p>

<h5 id="cluster-attributes">Cluster Attributes</h5>
<p>To understand what these different behaviors or characteristics are, we can analyze the attributes of each cluster in terms of the variables fed into the k-means algorithm.<br></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># profile clusters (mean % sales for each product area)
</span><span class="n">cluster_summary</span> <span class="o">=</span> <span class="n">data_for_clustering</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">"cluster"</span><span class="p">)[[</span><span class="s">"Dairy"</span><span class="p">,</span><span class="s">"Fruit"</span><span class="p">,</span><span class="s">"Meat"</span><span class="p">,</span><span class="s">"Vegetables"</span><span class="p">]].</span><span class="n">mean</span><span class="p">().</span><span class="n">reset_index</span><span class="p">()</span>
</code></pre></div></div>
<p><br>
Above code results in the following table:</p>

<table>
  <thead>
    <tr>
      <th><strong>Cluster</strong></th>
      <th><strong>Dairy</strong></th>
      <th><strong>Fruit</strong></th>
      <th><strong>Meat</strong></th>
      <th><strong>Vegetables</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>22.1%</td>
      <td>26.5%</td>
      <td>37.7%</td>
      <td>13.8%</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.2%</td>
      <td>63.8%</td>
      <td>0.4%</td>
      <td>35.6%</td>
    </tr>
    <tr>
      <td>2</td>
      <td>36.4%</td>
      <td>39.4%</td>
      <td>2.9%</td>
      <td>21.3%</td>
    </tr>
  </tbody>
</table>

<p><br>
For <em>Cluster 0</em> we see a reasonably significant portion of spend being allocated to each of the product areas.</p>

<p>For <em>Cluster 1</em> we see quite high proportions of spend being allocated to Fruit &amp; Vegetables, but very little to the Dairy &amp; Meat product areas. It could be hypothesised that these customers are following a vegan diet.</p>

<p>Finally customers in <em>Cluster 2</em> spend, on average, significant portions within Dairy, Fruit &amp; Vegetables, but very little in the Meat product area - so similarly, we would make an early hypothesis that these customers are more along the lines of those following a vegetarian diet.<br><br></p>

<hr>
<h1 id="application">
<a class="anchor" href="#application" aria-hidden="true"><span class="octicon octicon-link"></span></a>Application</h1>
<p>Although this is a straightforward solution, the fact that it is based on high-level product sectors will aid category managers and business executives in better understanding the client base.</p>

<p>Tracking these clusters over time would allow the client to more quickly react to dietary trends, and adjust their messaging and inventory accordingly.</p>

<p>Based on these clusters, the client will be able to target customers more accurately - promoting products and discounts to customers that are truly relevant to them - overall enabling a more customer focused communication strategy.<br><br></p>



                    
					
					<script src="/assets/js/codebutton.js"></script>

                </div>
                
                <div class="post-navigation">
                    
                    <a href="/Chi-Square-Test/" class="prev">
                        <div class="post-nav-arrow"><i class="ion ion-ios-arrow-round-back"></i> Previous </div>
                    </a>
                    
                    
                    <a href="#" class="next disabled">
                        <div class="post-nav-arrow">Next <i class="ion ion-ios-arrow-round-forward"></i></div>
                    </a>
                    
                </div>
                
            </div>
        </article> <!-- /.post -->
    </div>
</div>
    <footer class="footer">
    <div class="container">
        <div class="row">
            <div class="col col-12">
                <div class="footer-top">
                    <h2 class="logo-title">
                        <a href="/" class="logo-text">Wint Thandar Oo</a>
                    </h2>
                    <div class="top"><i class="ion ion-ios-arrow-up"></i></div>
                </div>
                <div class="footer-bottom">
                    <div class="copyright">
                        <p>&copy; 2023 Wint Thandar Oo Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a></p>
                    </div>
                    <div class="footer-social">
                        <ul class="list-reset">
                            <li><a href="https://github.com/Wint-Thandar"><i class="ion ion-logo-github"></i> Github</a></li>
                            <li><a href="https://www.linkedin.com/in/wintthandaroo/"><i class="ion ion-logo-linkedin"></i> Linkedln</a></li>
                            <li><a href="/feed.xml"><i class="ion ion-logo-rss"></i> Feed</a></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>
</footer> <!-- /.footer -->
    <!-- js here -->
<script src="/assets/js/jquery-3.3.1.min.js"></script>
<script src="/assets/js/jquery.waitforimages.min.js"></script>
<script src="/assets/js/jquery.fitvids.js"></script>
<script src="/assets/js/common.js"></script>
</body>

</html>